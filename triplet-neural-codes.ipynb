{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432,
     "status": "ok",
     "timestamp": 1560003670448,
     "user": {
      "displayName": "Himanshi Allahabadi",
      "photoUrl": "",
      "userId": "04533307834422124096"
     },
     "user_tz": -120
    },
    "id": "BVChthw96rSc",
    "outputId": "211c5797-18d7-4434-be7e-d88d8792ac5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Input, Lambda, concatenate\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.spatial import distance\n",
    "import keras\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7Zgwonn5p_3"
   },
   "source": [
    "### Task 2.1: triplet siamese network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1560009753973,
     "user": {
      "displayName": "Himanshi Allahabadi",
      "photoUrl": "",
      "userId": "04533307834422124096"
     },
     "user_tz": -120
    },
    "id": "uHmllJCh6wIo",
    "outputId": "2f366686-7b5f-40d4-8c7a-640fbb2d6ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "(80, 500, 32, 32, 3)\n",
      "(80, 500, 1)\n",
      "(20, 500, 32, 32, 3)\n",
      "(20, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "# get Cifar-100 data\n",
    "from keras.datasets import cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "n_classes = 100 # given\n",
    "input_shape = x_test.shape[1:]\n",
    "\n",
    "# get indices of sorted data so we can order out data by category\n",
    "idx = np.argsort(y_train, axis=None)\n",
    "\n",
    "x_train = x_train[idx].reshape(n_classes, -1, *input_shape)\n",
    "y_train = y_train[idx].reshape(n_classes, -1, 1)\n",
    "\n",
    "# select 80 classes for training data\n",
    "x_train_trip = x_train[:80]\n",
    "y_train_trip = y_train[:80]\n",
    "\n",
    "# select remaining 20 classes for test data\n",
    "x_test_trip = x_train[80:]\n",
    "y_test_trip = y_train[80:]\n",
    "\n",
    "# check shapes\n",
    "print(x_train_trip.shape)\n",
    "print(y_train_trip.shape)\n",
    "print(x_test_trip.shape)\n",
    "print(y_test_trip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PySpI0pB7Lqi"
   },
   "outputs": [],
   "source": [
    "def triplet_loss(ground_truth, network_output):\n",
    "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)\n",
    "    \n",
    "    for embedding in [anchor, positive, negative]:\n",
    "        embedding = tf.math.l2_normalize(embedding)\n",
    "    \n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
    "    \n",
    "    margin = 0.2 # define your margin, 0.2 filled in now so it compilesss and so we can test stuff\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2918osc_n5i"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n triples, with positive and negatives\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 3 empty arrays for the input image batch, where triplets[0] is the anchor\n",
    "    # triplets[1] is the positive match to the anchor, and pairs[2] is the negative match to the anchor\n",
    "    triplets = [np.zeros((batch_size, h, w, d)) for i in range(3)]\n",
    "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "#     targets = np.zeros((batch_size,))\n",
    "#     targets[batch_size//2:] = 1\n",
    "    targets = np.zeros((batch_size,))\n",
    "    for i in range(batch_size):\n",
    "      category = categories[i]\n",
    "      idx_1 = np.random.randint(0, n_examples)\n",
    "      triplets[0][i, :, :, :] = X[category, idx_1].reshape(w, h, d)\n",
    "      idx_2 = np.random.randint(0, n_examples)\n",
    "      triplets[1][i, :, :, :] = X[category, idx_2].reshape(w, h, d)\n",
    "      idx_3 = np.random.randint(0, n_examples)\n",
    "      category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "      triplets[2][i, :, :, :] = X[category_2, idx_3].reshape(w, h, d)\n",
    "#       print(category, category_2)\n",
    "    return triplets, targets\n",
    "  \n",
    "def batch_generator(batch_size, X):\n",
    "  while True:\n",
    "    triplets, targets = get_batch(batch_size, X)\n",
    "    yield (triplets, targets)\n",
    "  \n",
    "  \n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=100,epochs=1):\n",
    "  model.fit_generator(batch_generator(batch_size, X_train),steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGH_oPvx5e4V"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "613lEuca7DKw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def triplet_loss(ground_truth, network_output):\n",
    "\n",
    "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)        \n",
    "\n",
    "    for embedding in [anchor, positive, negative]:\n",
    "        embedding = tf.math.l2_normalize(embedding)\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
    "\n",
    "    margin = 0.15 # define your margin\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
    "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1025
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2747,
     "status": "ok",
     "timestamp": 1560010710835,
     "user": {
      "displayName": "Himanshi Allahabadi",
      "photoUrl": "",
      "userId": "04533307834422124096"
     },
     "user_tz": -120
    },
    "id": "GwrNzriE-vsZ",
    "outputId": "b2518603-9510-46a5-dde3-94968a40b81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 41472)             165888    \n",
      "_________________________________________________________________\n",
      "neural_codes (Dense)         (None, 2048)              84936704  \n",
      "=================================================================\n",
      "Total params: 86,733,184\n",
      "Trainable params: 86,648,192\n",
      "Non-trainable params: 84,992\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 2048)         86733184    input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 6144)         0           sequential_6[1][0]               \n",
      "                                                                 sequential_6[2][0]               \n",
      "                                                                 sequential_6[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 86,733,184\n",
      "Trainable params: 86,648,192\n",
      "Non-trainable params: 84,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "anchor_input = Input(input_shape)\n",
    "positive_input = Input(input_shape)\n",
    "negative_input = Input(input_shape)\n",
    "\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape,  kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "\n",
    "convnet.add(Conv2D(128, (3, 3), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.5))\n",
    "\n",
    "convnet.add(Conv2D(256, (3, 3), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "# convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.5))\n",
    "\n",
    "convnet.add(Conv2D(512, (3, 3), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "# convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dense(2048, name=\"neural_codes\", activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.summary()\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_anchor = convnet(anchor_input)\n",
    "encoded_positive = convnet(positive_input)\n",
    "encoded_negative = convnet(negative_input)\n",
    "\n",
    "\n",
    "outputs= concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name=\"merged_layer\")\n",
    "\n",
    "triplet_net = Model(inputs=[anchor_input, positive_input ,negative_input], outputs=outputs)\n",
    "\n",
    "\n",
    "triplet_net.compile(loss=triplet_loss, optimizer=keras.optimizers.Adadelta(1.2))\n",
    "\n",
    "triplet_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpWVI6fjSZbq"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n triplets, half same class, half different class\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    triplets = [np.zeros((batch_size, h, w, d)) for i in range(3)]\n",
    "    targets = np.zeros((batch_size,))\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        triplets[0][i, :, :, :] = X[category, idx_1].reshape(w, h, d)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "        triplets[1][i, :, :, :] = X[category, idx_2].reshape(w, h, d)\n",
    "        idx_3 = np.random.randint(0, n_examples)\n",
    "        category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "        triplets[2][i, :, :, :] = X[category_2, idx_3].reshape(w, h, d)\n",
    "    return triplets, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        triplets, targets = get_batch(batch_size, X)\n",
    "        yield (triplets, targets)\n",
    "\n",
    "def train_triplet_network(model, X_train, batch_size=64, steps_per_epoch=100, epochs=40):\n",
    "    model.fit_generator(batch_generator(batch_size, X_train), steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1361
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 779788,
     "status": "ok",
     "timestamp": 1560011495998,
     "user": {
      "displayName": "Himanshi Allahabadi",
      "photoUrl": "",
      "userId": "04533307834422124096"
     },
     "user_tz": -120
    },
    "id": "6vpaDsKS0obm",
    "outputId": "06de5e88-2d02-490e-c705-c11f8968939b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 121.0985\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 99.3938\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 99.2640\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 90.7098\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 90.7467\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 87.0404\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 86.5921\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 84.3718\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 85.6403\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 82.3017\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 79.1230\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 71.7878\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 63.8219\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 56.0324\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 47.0013\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 38.1787\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 29.4358\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 22.3815\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 16.5359\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 12.0643\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 8.5068\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 5.9281\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 4.1348\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 2.9685\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 2.2439\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 1.8633\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.6128\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.4353\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.2610\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 1.0874\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.9675\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.8689\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.7553\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6859\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6344\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6077\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.5955\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.5957\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6160\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6391\n"
     ]
    }
   ],
   "source": [
    "train_triplet_network(triplet_net, x_train_trip, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhNyAbYw5fDR"
   },
   "source": [
    "### Task 2.2: One-shot learning with triplet neural codes\n",
    "**a)**\n",
    "* Use neural codes from the triplet network with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction.\n",
    "* Explicitly state the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnQqfs56NqqT"
   },
   "outputs": [],
   "source": [
    "def generate_one_shot_task(N, X):\n",
    "  #generate positive and negative support sets\n",
    "  n_classes, n_examples, w, h, d = X.shape\n",
    "\n",
    "\n",
    "  categories = np.random.choice(range(n_classes), size=(N,), replace=False) #randomly choose N classes(20) from the total number of classes\n",
    "  indices = np.random.randint(0, n_examples, size=(N,)) #randomly select N indices\n",
    "  true_category = categories[0] #select the first category as the true categor\n",
    "  ex_anchor = np.random.choice(n_examples, replace=False, size=(1,)) #randomly choose 1 index for anchor(test) example image\n",
    "\n",
    "  #select the test image from the training set, from the true category, with index=ex_anchor\n",
    "  #why do we reshape here: because we will pass inputs to model as 3 arrays, each containing 20 images. The other two arrays will\n",
    "  #have N distinct images, 1 array from the true category and the other containing 20 images from remaining 19 classes\n",
    "\n",
    "  test_image = np.asarray([X[true_category, ex_anchor, :, :]]*N).reshape(N, w, h, d)\n",
    "\n",
    "#   print('shape of test img: ', test_image.shape)\n",
    "\n",
    "  positive_support_set= X[true_category, indices, :,:]\n",
    "\n",
    "#   print('shape of positive_support_set', positive_support_set.shape)\n",
    "\n",
    "  negative_categories= categories[1:]\n",
    "\n",
    "#   print('shape of negative_categories', negative_categories.shape)\n",
    "\n",
    "  Nth_category= np.random.choice(negative_categories, replace=False, size=(1,))\n",
    "#   print('Nth_category', Nth_category)\n",
    "\n",
    "  negative_categories= np.append(negative_categories, Nth_category)\n",
    "\n",
    "#   print('shape of negative_categories', negative_categories.shape)\n",
    "\n",
    " \n",
    "\n",
    "  negative_support_set= X[negative_categories, indices, :, :]\n",
    "#   print('shape of negative_support_set', negative_support_set.shape)\n",
    "  \n",
    "  triplets= [test_image, positive_support_set, negative_support_set]\n",
    "  return triplets\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4397,
     "status": "ok",
     "timestamp": 1560011577670,
     "user": {
      "displayName": "Himanshi Allahabadi",
      "photoUrl": "",
      "userId": "04533307834422124096"
     },
     "user_tz": -120
    },
    "id": "Wa1wBuMbNyQo",
    "outputId": "d9b8b379-8ab6-4c48-93bb-68a36d132641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 20.0% accuracy for 20-way one-shot learning\n"
     ]
    }
   ],
   "source": [
    "#GENERATE 250 ONE-SHOT TASKS\n",
    "\n",
    "\n",
    "k=250\n",
    "N=20\n",
    "\n",
    "#  Extract the dense layer\n",
    "# nodes_model = Model(inputs=triplet_net.input, outputs=triplet_net.get_layer(\"merged_layer\").output) \n",
    "\n",
    "nodes_model = triplet_net\n",
    "n_correct = 0\n",
    "\n",
    "for i in range(k):\n",
    "  inputs = generate_one_shot_task(N, x_test_trip)\n",
    "  probs = nodes_model.predict(inputs)\n",
    "#   print('shape probs', probs.shape)\n",
    "  #  Extract the three embedding vectors\n",
    "  anchor = probs[:,0:2048]\n",
    "  pos = probs[:,2048:4096]\n",
    "  neg = probs[:,4096:6144]\n",
    "  \n",
    "  #calculating the accuracy\n",
    "  \n",
    "  l2_dist=0\n",
    "  \n",
    "  for j in range(N): \n",
    "      l2_pos = distance.euclidean(anchor[j], pos[j])\n",
    "      l2_neg = distance.euclidean(anchor[j], neg[j])\n",
    "      l2_dist += l2_pos - l2_neg\n",
    "  if l2_dist > 0:\n",
    "    n_correct += 1\n",
    "percent_correct = (100.0*n_correct / k)\n",
    "print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Question 2.1 himanshi.ipynb",
   "provenance": [
    {
     "file_id": "1AWJ0S7vXjH8JkaUVP1mu7SGCoC2tW4qI",
     "timestamp": 1558357831325
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
